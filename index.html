
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ReconFusion</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://reconfusion.github.io/img/overview_combined.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1711">
    <meta property="og:image:height" content="576">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://reconfusion.github.io/"/>
    <meta property="og:title" content="ReconFusion: 3D Reconstruction with Diffusion Priors" />
    <meta property="og:description" content="3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches."/>

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="ReconFusion: 3D Reconstruction with Diffusion Priors" />
    <meta name="twitter:description" content="3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches."/>
    <meta name="twitter:image" content="https://reconfusion.github.io/img/overview_combined.png" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤”</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
	<link rel="stylesheet" href="css/fontawesome.all.min.css">
	<link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">


	<!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"></script>
  <script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'G-8ZERS5BVPS');
  </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
	<script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/synced_video_selector.js"></script>

</head>

<body style="padding: 1%; width: 100%">
    <div class="container-lg text-center" style="max-width: 1500px; margin: auto;" id="main">
    <!-- <div class="container" id="main"> -->
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>3DGS-Enhancer</b>: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</br> 
            </h2>
        </div>
        <div class="row text-center">
<div class="col-md-3">
    </div>
            <!-- <div class="col-md-6 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://xiliu8006.github.io/">
                            Xi Liu
                        </a><sup>1</sup>*
                    </li>
                    <li>
                        <a href="">
                            Chaoyi Zhou
                        </a><sup>2</sup>*
                    </li>
                    <li>
                        <a href="">
                          Siyu Huang
                        </a><sup>2</sup>
                    </li>
                </ul>
            </div> -->


<div class="col-md-3">
    </div>
            <!-- <div class="col-md-12 text-center">
                <sup>1</sup>Clemson University

            </div> -->
            <div class="col-md-12 text-center">
                * equal contribution
            </div> </div>


        <div class="row text-center">
					
			     <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Supplement</span>
                </a>
              </span>
			</div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="teaser-video-ours" width="100%" autoplay loop muted controls>
                  <source src="videos/teaser/teaser.mp4" type="video/mp4" />
                </video>
<!-- 
                <video id="teaser-video-ours" width="100%" autoplay loop muted>
                  <source src="videos/teaser/grid_ours.mp4" type="video/mp4" />
                </video>
                <video id="teaser-video-zipenrf" width="100%" autoplay loop muted hidden>
                  <source src="videos/teaser/grid_zipnerf.mp4" type="video/mp4" />
                </video>

                <div class="switch-container-wrapper">
                    <div class="switch-container">
                        <span class="switch-label">Ours</span>
                        <label class="switch">
                            <input type="checkbox" id="teaserVideoSwitch" onclick="selectTeaserVideo()">
                            <div class="slider round"></div>
                        </label>
                        <span class="switch-label">Zip-NeRF</span>
                    </div>
                </div>
                <script>
                    function selectTeaserVideo() {
                      var video_ours = document.getElementById("teaser-video-ours");
                      var video_zipnerf = document.getElementById("teaser-video-zipenrf");
                      var videoSwitch = document.getElementById("teaserVideoSwitch");
                      if (videoSwitch.checked) {
                        video_zipnerf.hidden = false;
                        video_ours.hidden = true;
                      } else {
                        video_zipnerf.hidden = true;
                        video_ours.hidden = false;
                      }
                    }
                </script>
 -->
			</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                  Novel-view synthesis aims to generate novel views of a scene from multiple input images or videos, and recent advancements like 3D Gaussian splatting (3DGS) have achieved notable success in producing photorealistic renderings with efficient pipelines. However, generating high-quality novel views under challenging settings, such as sparse input views, remains difficult due to insufficient information in under-sampled areas, often resulting in noticeable artifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing the representation quality of 3DGS representations. We leverage 2D video diffusion priors to address the challenging 3D view consistency problem, reformulating it as achieving temporal consistency within a video generation process. 3DGS-Enhancer restores view-consistent latent features of rendered novel views and integrates them with the input views through a spatial-temporal decoder. The enhanced views are then used to fine-tune the initial 3DGS model, significantly improving its rendering performance. Extensive experiments on large-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields superior reconstruction performance and high-fidelity rendering results compared to state-of-the-art methods. The project webpage is \href{https://3dgs-enhancer.github.io/}{\color{pink} 3dgs-enhancer.github.io}.
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <image src="img/pipeline.png" width=90% style="display: block; margin: auto;"></image>
                <p class="text-justify">
                  An overview of the proposed 3DGS-Enhancer framework for 3DGS representation enhancement. We learn 2D video diffusion priors on a large-scale novel view synthesis dataset to enhance the novel views rendered from the 3DGS model on a novel scene. Then, the enhanced views and input views jointly fine-tune the 3DGS model
                </p>
            </div>
        </div><br><br>
	<div class="row">
		<div class="col-md-8 col-md-offset-2">
		<h3>3DGS-Enhancer can enchance the low quality images from 3D Gaussian splatting</h3><br>
                <video id="co3d-grid" width="100%" autoplay loop muted controls>
                  <source src="videos/results/3DGS-Enhancer-3x5-video12-combined.mp4" type="video/mp4" />
                </video>
                <br>
                    <p class="text-justify" style="text-align: center;">3DGS-Enhancer can enhance scenes represented by 3D Gaussians</p>
			</div>
        </div>


        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
				          3DGS-Enhancer compared with 3DGS
                </h3><br>

                <div class="text-center ">
                    <ul class="nav nav-pills center-pills">
                        <li class="method-pill active" data-value="input_video"
                            onclick="selectCompVideo(this, activeScenePill)"><a>3D Gaussian Splatting </a></li>
                    </ul>
                </div>

                <script>
                    activeMethodPill = document.querySelector('.method-pill.active-pill');
                    activeScenePill = document.querySelector('.scene-pill.active-pill');
                    activeModePill = document.querySelector('.mode-pill.active-pill');
                </script>
                
                <div class="text-center">
                    <div class="video-container">
                        <video class="video" style="height: 280px; max-width: 100%;" m id="compVideo0" loop playsinline autoplay muted>
                            <source src="videos/comparison/video-3/input_video/25f7dbc10c0e2a9a8ffa33c35660d9090b6f7df6478653e351b3cb1195f7347b.mp4" />
                        </video>
                    </div>
                    <div class="text-center" style="color: black;" id="mode-pills">
                        <div class="btn-group btn-group-sm">
                            <span class="btn btn-primary mode-pill active" data-value="rgb"
                                onclick="selectCompVideo(activeMethodPill, activeScenePill, null, this)">
                                RGB
                            </span>
                        </div>
                    </div>


                    <br>
                    <p class="text-justify" style="text-align: center;">
                        3D Gaussian Splatting (left) vs 3DGS-Enhancer (right). Scene trained on <span id="compVideoValue">3</span> views. Try selecting different methods and scenes!
                    </p>
                    <script>
                        video0 = document.getElementById("compVideo0");
                        video0.addEventListener('loadedmetadata', function() {
                            if (activeVidID == 0 && select){
                                video0.play();
                                // print video size
                                console.log(video0.videoWidth, video0.videoHeight);
                                video0.hidden = false;
                                // video1.hidden = true;
                            }
                        });
                        
                    </script>

                    <div class="pill-row scene-pills" id="scene-pills">
                        <span class="pill scene-pill" data-value="0a78c25f77c1ba1d1a3f07c18c9735ae1254a9a71290734b8836eefbefaadbc7" onclick="selectCompVideo(activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/0a78_ref_frame_00002.png" alt="DL3DV/0a78" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="03f5c560f5725ad6ca55fd7e6c0af4c4c7a7ca94c444a584f2a9f316d3b35ea2" onclick="selectCompVideo(activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/03f5_ref_frame_00002.png" alt="DL3DV/03f5" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="efdf19ca82bba7bccc73f64273405d077abd61dd2f5339a0a642bc75d7d900ec" onclick="selectCompVideo(activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/efdf_ref_frame_00002.png" alt="DL3DV/efdf" width="64">
                        </span>
                    </div>

                    <script>
                        activeMethodPill = document.querySelector('.method-pill.active-pill');
                        activeScenePill = document.querySelector('.scene-pill.active-pill');
                        activeModePill = document.querySelector('.mode-pill.active-pill');
                    </script>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
				  <p class="text-justify">
                    <textarea id="bibtex" class="form-control" readonly>
@article{
  check update version 1
	}</textarea></p>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
